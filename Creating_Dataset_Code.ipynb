{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import scipy.io as sci\n",
    "import numpy as np\n",
    "import torch.utils.data as tud\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Dataset\n",
    "\n",
    "Validation_Set = sci.loadmat('/home/urabe/Documents/Research/Professor Marcia/DataSet For House Numbers/Mat Datasets/Validation_Set.mat')\n",
    "\n",
    "gray_data_train = sci.loadmat('/home/urabe/Documents/Research/Professor Marcia/DataSet For House Numbers/Mat Datasets/train_blur1_gray_32X32.mat')\n",
    "gray_data_clean = sci.loadmat('/home/urabe/Documents/Research/Professor Marcia/DataSet For House Numbers/Mat Datasets/train_gray_32X32.mat')\n",
    "gray_data_test = sci.loadmat('/home/urabe/Documents/Research/Professor Marcia/DataSet For House Numbers/Mat Datasets/test_blur1_gray_32X32.mat')\n",
    "test_clean = sci.loadmat('/home/urabe/Documents/Research/Professor Marcia/DataSet For House Numbers/Mat Datasets/test_gray_32X32.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 32, 40000])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Validation_Set.keys()\n",
    "Val = Validation_Set['A']\n",
    "Val = torch.Tensor(Val)\n",
    "Val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the tensor, adding missing channel, and correcting channel order\n",
    "\n",
    "\n",
    "#Converting the dataset to a tensor and adding missing channels\n",
    "\n",
    "#blur1_tensor = gray_data_train['blur_train_1']\n",
    "#blur1_tensor = torch.Tensor(blur1_tensor)\n",
    "#blur1_tensor = blur1_tensor.permute(2,0,1)\n",
    "#blur1_tensor = torch.unsqueeze(blur1_tensor,1)\n",
    "\n",
    "\n",
    "#Converting our clean data into a tensory and adding missing channel\n",
    "\n",
    "#clean = gray_data_clean['train_gray']\n",
    "#clean = torch.Tensor(clean)\n",
    "#clean = clean.permute(2,0,1)\n",
    "#clean = torch.unsqueeze(clean,1)\n",
    "\n",
    "\n",
    "#Converting our Validation Set data into a tensory and adding missing channel\n",
    "\n",
    "Val_blur = Validation_Set['A']\n",
    "Val_blur = torch.Tensor(Val_blur)\n",
    "Val_blur = Val_blur.permute(2,0,1)\n",
    "Val_blur = torch.unsqueeze(Val_blur,1)\n",
    "\n",
    "#Converting our Validation Set data into a tensory and adding missing channel\n",
    "\n",
    "Val_clean = Validation_Set['A']\n",
    "Val_clean = torch.Tensor(Val_clean)\n",
    "Val_clean = Val_clean.permute(2,0,1)\n",
    "Val_clean = torch.unsqueeze(Val_clean,1)\n",
    "\n",
    "\n",
    "\n",
    "#Converting our test data into a tensory and adding missing channel\n",
    "#final = gray_data_test['blur_test_1']\n",
    "#final = torch.Tensor(final);\n",
    "#final = final.permute(2,0,1)\n",
    "#final = torch.unsqueeze(final,1)\n",
    "\n",
    "#Converting our test data into a tensory and adding missing channel\n",
    "\n",
    "#test_clean = test_clean['test_gray']\n",
    "#test_clean = torch.Tensor(test_clean)\n",
    "#test_clean = test_clean.permute(2,0,1)\n",
    "#test_clean = torch.unsqueeze(test_clean,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying average pooling to dataset\n",
    "\n",
    "\n",
    "#train_pool16x16 = torch.empty(73257,16,16)\n",
    "#m = nn.AvgPool2d(2, stride = 2)\n",
    "\n",
    "#for i in range(0,73257):\n",
    "#    train_pool16x16[i,:,:] = m(blur1_tensor[i,:,:,:])\n",
    "    \n",
    "#-----------------------------------------------------------------------------------------------------\n",
    "    \n",
    "#train_pool8x8 = torch.empty(73257,8,8)\n",
    "#m = nn.AvgPool2d(4, stride = 4)\n",
    "\n",
    "#for i in range(0,73257):\n",
    "#    train_pool8x8[i,:,:] = m(blur1_tensor[i,:,:,:]);\n",
    "    \n",
    "#-----------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "Val_pool16x16 = torch.empty(40000,16,16)\n",
    "m = nn.AvgPool2d(2, stride = 2)\n",
    "\n",
    "for i in range(0,40000):\n",
    "    Val_pool16x16[i,:,:] = m(Val_blur[i,:,:,:]);\n",
    "    \n",
    "#-----------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "#test_pool16x16 = torch.empty(26032,16,16)\n",
    "#m = nn.AvgPool2d(2, stride = 2)\n",
    "\n",
    "#for i in range(0,26032):\n",
    "#    test_pool16x16[i,:,:] = m(final[i,:,:,:])\n",
    "    \n",
    "#-----------------------------------------------------------------------------------------------------\n",
    "    \n",
    "#test_pool8x8 = torch.empty(26032,8,8)\n",
    "#m = nn.AvgPool2d(4, stride = 4)\n",
    "\n",
    "#for i in range(0,26032):\n",
    "#    test_pool8x8[i,:,:] = m(final[i,:,:,:]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying poisson noise to the average pooling\n",
    "#Scaling poisson noise by 2\n",
    "\n",
    "\n",
    "#train_poisson_noise_16x16 = np.empty([73257,16,16])\n",
    "\n",
    "#for i in range(0,73257):\n",
    "#    train_poisson_noise_16x16[i,:,:] = np.random.poisson(train_pool16x16[i,:,:]);\n",
    "\n",
    "#train_poisson_noise_16x16 = torch.Tensor(train_poisson_noise_16x16)\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------\n",
    "\n",
    "#train_poisson_noise_8x8 = np.empty([73257,8,8])\n",
    "\n",
    "#for i in range(0,73257):\n",
    "#    train_poisson_noise_8x8[i,:,:] = np.random.poisson(train_pool8x8[i,:,:]);\n",
    "\n",
    "#train_poisson_noise_8x8 = torch.Tensor(train_poisson_noise_8x8)\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "val_noise_16x16 = np.empty([40000,16,16])\n",
    "\n",
    "for i in range(0,40000):\n",
    "    val_noise_16x16[i,:,:] = np.random.poisson(Val_pool16x16[i,:,:]);\n",
    "\n",
    "val_noise_16x16 = torch.Tensor(val_noise_16x16)\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "#test_poisson_noise_16x16 = np.empty([26032,16,16])\n",
    "\n",
    "#for i in range(0,26032):\n",
    "#    test_poisson_noise_16x16[i,:,:] = np.random.poisson(test_pool16x16[i,:,:]);\n",
    "\n",
    "#test_poisson_noise_16x16 = torch.Tensor(test_poisson_noise_16x16)\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------\n",
    "\n",
    "#test_poisson_noise_8x8 = np.empty([26032,8,8])\n",
    "\n",
    "#for i in range(0,26032):\n",
    "#    test_poisson_noise_8x8[i,:,:] = np.random.poisson(test_pool8x8[i,:,:]);\n",
    "\n",
    "#test_poisson_noise_8x8 = torch.Tensor(test_poisson_noise_8x8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding the channel that was lost when downsappling and adding poisson noise\n",
    "\n",
    "#train_poisson_noise_16x16 = torch.unsqueeze(train_poisson_noise_16x16,1)\n",
    "#train_poisson_noise_8x8 = torch.unsqueeze(train_poisson_noise_8x8, 1)\n",
    "\n",
    "val_noise_16x16 = torch.unsqueeze(val_noise_16x16,1)\n",
    "\n",
    "#test_poisson_noise_16x16 = torch.unsqueeze(test_poisson_noise_16x16,1)\n",
    "#test_poisson_noise_8x8 = torch.unsqueeze(test_poisson_noise_8x8, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(331.)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30164\n"
     ]
    }
   ],
   "source": [
    "#Normalization of the Dataset\n",
    "\n",
    "\n",
    "#Input_16x16 = torch.empty(73257,1,16,16)\n",
    "#Clean_Norm = torch.empty(73257,1,32,32)\n",
    "#test_16x16 = torch.empty(26032,1,16,16)\n",
    "#test_norm = torch.empty(26032,1,32,32)\n",
    "val_16x16 = torch.empty(40000,1,16,16)\n",
    "\n",
    "val_max = []\n",
    "#maxx = []\n",
    "#maxx_clean = []\n",
    "#test_maxx = []\n",
    "#test_clean_max = []\n",
    "\n",
    "\n",
    "\n",
    "#Changes Index if ran the previous code, First for loop gets max value\n",
    "#Then use the undex found using max(maxx)\n",
    "\n",
    "#for i in range(0,73257):\n",
    "#    maxx.append(torch.max(train_poisson_noise_16x16[i]))\n",
    "    \n",
    "#    if maxx[i] == 318:\n",
    "#        print(i)\n",
    "\n",
    "        \n",
    "#max(maxx)\n",
    "        \n",
    "#This normalizies all the data using the max value\n",
    "\n",
    "#for i in range(0, 73257):\n",
    "#    Input_16x16[i] = train_poisson_noise_16x16[i] / torch.max(train_poisson_noise_16x16[27203])\n",
    "\n",
    "\n",
    "#normalizing Validation Set\n",
    "#---------------------------------------------------------------------------------------------------------------\n",
    "for i in range(0,40000):\n",
    "    val_max.append(torch.max(val_noise_16x16[i]))\n",
    "    \n",
    "    if val_max[i] == 331:\n",
    "        print(i)\n",
    "    \n",
    "max(val_max)\n",
    "\n",
    "for i in range(0,40000):\n",
    "    val_16x16[i] = val_noise_16x16[i] / torch.max(val_noise_16x16[30164])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "Clean_val = torch.empty(40000,1,32,32)\n",
    "Clean_val_max = []\n",
    "\n",
    "for i in range(0,40000):\n",
    "    Clean_val_max.append(torch.max(Val_clean[i]))\n",
    "    \n",
    "#max(Clean_val_max)\n",
    "\n",
    "for i in range(0,40000):\n",
    "    Clean_val[i] = Val_clean[i]/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max((Clean_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#for i in range(0, 73257):\n",
    "#    maxx_clean.append(torch.max(clean[i]))\n",
    "#    if maxx_clean == 255:\n",
    "#        print(i)\n",
    "\n",
    "#max(maxx_clean)\n",
    "\n",
    "\n",
    "#for i in range(0, 73257):\n",
    "#    Clean_Norm[i] = clean[i] / 255\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5062\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for i in range(0,26032):\n",
    "    test_maxx.append(torch.max(test_poisson_noise_16x16[i]))\n",
    "    \n",
    "    if test_maxx[i] == 318:\n",
    "        print(i)\n",
    "\n",
    "max(test_maxx)\n",
    "\n",
    "for i in range(0, 26032):\n",
    "    test_16x16[i] = test_poisson_noise_16x16[i] / torch.max(test_poisson_noise_16x16[5062])\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(0, 26032):\n",
    "    test_clean_max.append(torch.max(test_clean[i]))\n",
    "    \n",
    "    if test_clean_max == 255:\n",
    "        print(i)\n",
    "\n",
    "for i in range(0, 26032):\n",
    "    test_norm[i] = test_clean[i] / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving tensors as numpys\n",
    "\n",
    "\n",
    "#np.save('/home/urabe/Documents/Research/Professor Marcia/DataSet For House Numbers/Final_Dataset/Clean_Norm',Clean_Norm.numpy())\n",
    "#np.save('/home/urabe/Documents/Research/Professor Marcia/DataSet For House Numbers/Final_Dataset/Input_16x16',Input_16x16.numpy())\n",
    "\n",
    "np.save('/home/urabe/Documents/Research/Professor Marcia/DataSet For House Numbers/Final_Dataset/Validation_16x16',val_16x16.numpy())\n",
    "np.save('/home/urabe/Documents/Research/Professor Marcia/DataSet For House Numbers/Final_Dataset/Clean_Val',Clean_val.numpy())\n",
    "\n",
    "\n",
    "#np.save('/home/urabe/Documents/Research/Professor Marcia/DataSet For House Numbers/Final_Dataset/Test_Norm',test_norm.numpy())\n",
    "#np.save('/home/urabe/Documents/Research/Professor Marcia/DataSet For House Numbers/Final_Dataset/Test_16x16',test_16x16.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
